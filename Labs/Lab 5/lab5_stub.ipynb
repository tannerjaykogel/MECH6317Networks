{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5\n",
    "#### Tanner Kogel tjk190000\n",
    "##### Mech 6317.001: Dynamics of Complex Networks & Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from numpy import zeros, dot, array\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import string\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7.13: Modularity\n",
    "\n",
    "The first function below calculates modularity for *directed* networks and also returns the maximum modularity value $Q_{\\text{max}}$ (NetworkX's modularity function does not report the $Q_{\\text{max}}$ value). The second function calculates scalar assortativity (NetworkX's assortativity functions differ from our book definition). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modularity(G,c):\n",
    "    d = dict()\n",
    "    for k,v in enumerate(c):\n",
    "        for n in v:\n",
    "            d[n] = k\n",
    "    L = 0\n",
    "    for u,v,data in G.edges.data():\n",
    "        L += data['weight']\n",
    "    Q, Qmax = 0,1\n",
    "    for u in G.nodes():\n",
    "        for v in G.nodes():\n",
    "            if d[u] == d[v]:\n",
    "                Auv = 0\n",
    "                if G.has_edge(v,u):\n",
    "                    Auv = G[v][u]['weight']\n",
    "                Q += ( Auv - G.in_degree(u,weight='weight')*G.out_degree(v,weight='weight')/L )/L\n",
    "                Qmax -= ( G.in_degree(u,weight='weight')*G.out_degree(v,weight='weight')/L )/L\n",
    "    return Q, Qmax\n",
    "\n",
    "def scalar_assortativity(G,d):\n",
    "    x = zeros(G.number_of_nodes())\n",
    "    for i,n in enumerate(G.nodes()):\n",
    "        x[i] = d[n]\n",
    "\n",
    "    A = nx.to_numpy_array(G).T # use updated form of adjacency matrix\n",
    "    #A = array(nx.adjacency_matrix(G).todense().T)\n",
    "    M = 2*A.sum().sum()\n",
    "    ki = A.sum(axis=1) #row sum is in-degree\n",
    "    ko = A.sum(axis=0) #column sum is out-degree\n",
    "    mu = ( dot(ki,x)+dot(ko,x) )/M\n",
    "\n",
    "    R, Rmax = 0, 0\n",
    "    for i in range(G.number_of_nodes()):\n",
    "        for j in range(G.number_of_nodes()):\n",
    "             R += ( A[i,j]*(x[i]-mu)*(x[j]-mu) )/M\n",
    "             Rmax += ( A[i,j]*(x[i]-mu)**2 )/M\n",
    "\n",
    "    return R, Rmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIFA exports by geographic region is assortatively mixed: 0.1200/0.5505\n",
      "FIFA exports by importers/exporters is disassortatively mixed: -0.0185/0.5748\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_weighted_edgelist('fifa1998.edgelist',create_using=nx.DiGraph)\n",
    "\n",
    "c = {\n",
    "    'group1': {'Argentina','Brazil','Chile','Mexico','Colombia','Jamaica','Paraguay'},\n",
    "    'group2': {'Japan','SouthKorea'},\n",
    "    'group3': {'UnitedStates'},\n",
    "    'group4': {'Nigeria','Morocco','SouthAfrica','Cameroon','Tunisia','Iran','Turkey'},\n",
    "    'group5': {'Scotland','Belgium','Austria','Germany','Denmark','Spain','France','GreatBritain','Greece','Netherlands','Norway','Portugal','Italy','Yugoslavia','Romania','Bulgaria','Croatia','Switzerland'}\n",
    "    }\n",
    "Q, Qmax = modularity(G,c.values())\n",
    "print('FIFA exports by geographic region is assortatively mixed: %1.4f/%1.4f' % (Q,Qmax))\n",
    "\n",
    "c = {\n",
    "    'exporters': {'Argentina','Brazil','Chile','Colombia','Mexico','Scotland','Belgium','Austria','Denmark','France','Greece','Netherlands','Portugal','Yugoslavia','Croatia','Jamaica','Cameroon','Nigeria','Morocco','Tunisia'},\n",
    "    'importers': {'Paraguay','SouthKorea','UnitedStates','SouthAfrica','Iran','Turkey','Germany','Spain','GreatBritain','Norway','Italy','Romania','Bulgaria','Switzerland','Japan'}\n",
    "    }\n",
    "Q, Qmax = modularity(G,c.values())\n",
    "print('FIFA exports by importers/exporters is disassortatively mixed: %1.4f/%1.4f' % (Q,Qmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modularity of the FIFA exports network is positive, or assortatively mixed when grouped by geographical region. This means that of players is contracetd to another countries that they are not native to, there are more instances where that player is contracted to a country that is within the same region from which their home country is from, than would be expected if they were randomly assigned to a different country based on how many players that country imports. In other words, more often than not, a player that will play for a different country will play for a country that is geographically close to their home country.\n",
    "\n",
    "The modularity of the FIFA exports network negative, or disassortatively mixed when grouped by importers and exporters. This means that for players that are contracted to countries they are not native to, they are more likely to be native to a country that is an \"exporter,\" meaning that more players from that country are contracted to other countries than players from other countries are conracted to them, and be contrated to a counry that is an \"importer,\" meaning that more non-native players are contracted to that country than players native to that country are contracted to other countries. This makes logical sense, because it is expected that countries that import many players are more like to get those players from countries that export a large number of players, and players from countries that typically export many players are likel to go to a country that imports many players, rather than another exporting country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7.13: Assortativite Mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assortativity by GDP: -0.0005\n",
      "Assortativity by life expectancy: 0.1281\n",
      "Assortativity by tariff: 0.1191\n"
     ]
    }
   ],
   "source": [
    "gdp = pickle.load(open('gdp.pkl','rb'))\n",
    "life_expectancy = pickle.load(open('life_expectancy.pkl','rb'))\n",
    "tariff = pickle.load(open('tariff.pkl','rb'))\n",
    "\n",
    "G = nx.read_weighted_edgelist('world_trade_2014.edgelist',create_using=nx.DiGraph)\n",
    "\n",
    "R, Rmax = scalar_assortativity(G,gdp)\n",
    "print('Assortativity by GDP: %1.4f' % (R/Rmax))\n",
    "R, Rmax =  scalar_assortativity(G,life_expectancy)\n",
    "print('Assortativity by life expectancy: %1.4f' % (R/Rmax))\n",
    "R, Rmax =  scalar_assortativity(G,tariff)\n",
    "print('Assortativity by tariff: %1.4f' % (R/Rmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The world trade network is disassortatively mixed by a very small margin when measured by GDP. This means that the countries that a given country chooses to trade with will more often have a significantly different GDP, but there is typically not much correlation between who a country chooses to trade with and their GDP because the assortativity is very nearly 0, meaning that the relationship very closely mimics the random baseline when grouped by GDP.\n",
    "\n",
    "The world trade network is assortatively mixed when measured by life expectency. This means that a typical country trades more often with countries of similar life expectency, rather than a life expectency that is drastically different. This largely may be due to geographical region. It can be expected that countries that are geographically close can have a similar life expectency and that these countries also likely engage in lots of trade due to their geographical proximity. These two factors can contribute to the small assortive mixing seen in the graph.\n",
    "\n",
    "The world trade network is assortatively mixed when measured by tariff. This means that a typical country trades more often with countries that have a similar tariff value, rather than a dramatically different tariff value. It is typically undesireable to trade with large tariffs as that is additional price that must be paid. The assortative mixing of this graph makes sense as the countries that have low tariff values would likely get a higher pick of the draw when choosing who to trade with, and they would likely choose other countries with low tariffs to maximise profit, leading to the assortatively mixed graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algebraic activities and diagram of cut set sizing increase are shown in the end of the PDF document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tweets are examples in which grouping hashtags by co-occurance in tweets can help find hashtags of similar meaining:\n",
    "\n",
    "    #RadioverFM - Coldplay estrena canciones de su nuevo disco #Xalapa #Veracruz #MÃ©xico https://t.co/qhHT90AlfX https://t.co/9Y3KNmU82O\n",
    "    Good old Lady C. Standing her ground and morals #ImACeleb #ImACelebrity\n",
    "    \n",
    "Where the first tweet has multiple hashtags related to the geogrpahical location of cities in mexico where a radio station reaches. In the second tweet there are two hashtags, #ImACeleb and #ImACelebrity which shows that common occurence of putting multiple hashtags that are similar in a post to boost engagement and viewability. In both instances, similar hashtags occur in the same tweet, which is why we are trying to create a network of hashtags in which edges represent co-occurences of hashtags in tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tweet is an example of co-occuring hashtags that do not have a similar meaning:\n",
    "\n",
    "    New #job opening at Community Health Sys in #Tucson - # 236-005 #LPN - Full-time - Urgent Care-Duval Mine Road #jobs\n",
    "\n",
    "Because while #job and #jobs is another example of similar hashtags being in the same tweet, #tucson is only relevant to this specific tweet, and is not overall related to #job or #jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data from raw_twitter.json and trim to get text from tweets only written out to file raw_tweets.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_twitter.json' , 'r' , encoding='utf-8') as fin:    # open file to read tweets from\n",
    "    with open('raw_tweets.txt' , 'w' , encoding='utf-8') as fout: # open file to write raw tweets to\n",
    "        for idx,line in enumerate(fin):                           # repeat for every line in the json file\n",
    "            if idx > 0:                                           # I was getting an error for the first line saying it wasn not in correct JSON format??\n",
    "                json_line = json.loads(line)                      # load in json data\n",
    "                tweet = json_line['text']                         # get just text information\n",
    "                twt_lines = tweet.split('\\n')                     # get list of all lines of tweet\n",
    "                tweet = ' '.join(twt_lines)                       # rejoin lines of tweet on single line\n",
    "                fout.write(tweet)                                 # write out text information to output file\n",
    "                fout.write('\\n')                                  # create new line between entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data from raw_tweets.txt and trim to get text from hashtags only written out to file hashtag_sets.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_tweets.txt' , 'r' , encoding='UTF-8') as fin:        # open file to read tweets from\n",
    "    with open('hashtag_sets.txt' , 'w' , encoding='UTF-8') as fout: # open file to write raw tweets to\n",
    "        for line in fin:                                            # repeat for every line from input file\n",
    "            strip_line = line.strip()                               # get rid of extraneous whitespace\n",
    "            line = strip_line.lower()                               # work in all lowercase\n",
    "            text_list = line.split('#')                             # create list of strings seperated by hashtags\n",
    "            h_list = ['']*len(text_list)                            # create list of hashtags\n",
    "            h_idx = 0;                                              # hashtag index\n",
    "            for idx,i in enumerate(text_list):                      # loop for each hastag appearance and keep track of the index\n",
    "                if idx > 0 and i.isspace()==False and len(i) > 0:   # only include alphanumeric values that come immediately after hashtags\n",
    "                    if i[0].isalnum():                              # first character is alphanumeric\n",
    "                        i_strip = i.strip()                         # get rid of extrneous whitespace\n",
    "                        spaces = i_strip.split(' ')                 # end hashtags when a space is present\n",
    "                        tabs = spaces[0].split('\\\\t')               # end hashtags when a tab is present\n",
    "                        newlines = tabs[0].split('\\\\n')             # end hashtags when a newline is present\n",
    "                        valid_h = newlines[0]                       # valid hashtag candidate\n",
    "                        while valid_h.isalnum() == False:           # string is not alphanumeric\n",
    "                            valid_h = valid_h[:-1]                  # remove last character from \n",
    "                        h_list[h_idx] = valid_h                     # new hashtag in hashtag list\n",
    "                        h_idx += 1                                  # indicate new hahstag by increaseing indeces\n",
    "            h_list_trim = ['']*h_idx                                # create list of hashtags with corret number of strings\n",
    "            for idx, i in enumerate(h_list_trim):                   # loop for each hashtag\n",
    "                h_list_trim[idx] = h_list[idx]                      # trimmed hashtag list does not have any empty hashtags\n",
    "            hashtags = ' '.join(h_list_trim)                        # create new string of all hashtags in a tweet seperated by a space\n",
    "            fout.write(hashtags)                                    # write out hashtags onto each line of the output file\n",
    "            fout.write('\\n')                                        # new line between each entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meaning of an empty line in the file hashtag_sets.txt represents a line in the data, or a single tweet, that does not have any hashtags in it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file generated by the above code creates a hypergraph of hashtags within a tweet, wherein the hashtag sets on each line represent nodes that are connected by a hyperedge which represents the tweet in which all the listed hashtags make an appearance. We do not analyze this hypergraph because we are less interested in the specific instances in which tweets appear together and more intereseted in how we can find communities of hashtags that represent similar posts based on how often these certain hashtags are used in the same tweet over the span of a very large network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an undirected graph from the hashtag_sets.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph() # initialize G as a graph\n",
    "\n",
    "with open('hashtag_sets.txt' , 'r' , encoding='UTF-8') as fin: # open file to read in hashtag sets\n",
    "    \n",
    "    for line in fin:                                           # repeat for every line or set of hashtags\n",
    "        \n",
    "        strip_line = line.strip()                              # get rid of extraneous whitespace\n",
    "        hashtag_set = strip_line.split(' ')                    # get list of hashtags in the set\n",
    "        \n",
    "        if len(hashtag_set) > 1: # tweet has at least two hashtags\n",
    "                        \n",
    "            # add edge/weight for pair into the network\n",
    "            for h1,h2 in itertools.combinations(hashtag_set,2): # loop for every pair in the hashtag set\n",
    "                if h1 == h2:                                    # self-loop\n",
    "                    w = 2                                       # weight has to be doubled\n",
    "                else:                                           # pair is of different nodes\n",
    "                    w = 1                                       # add single weight for non-self-loop\n",
    "                if G.has_node(h1) and G.has_node(h2):           # both hashtags already exist in the network\n",
    "                    if G.has_edge(h1,h2):                       # hashtags already have an edge\n",
    "                        G[h1][h2]['weight'] += w                # add weight to edge\n",
    "                    else:                                       # hashtags do not have an edge\n",
    "                        G.add_edge(h1,h2,weight=w)              # add edge (first pairing therefore weight = 1)\n",
    "                else:                                           # at least one node does not exist\n",
    "                    G.add_edge(h1,h2,weight=w)                  # add edge to represent hashtag pair (will add in nodes that don't already exist)\n",
    "                    \n",
    "        else: # tweet contains single or no hashtags\n",
    "            \n",
    "            if len(hashtag_set[0]) == 0:            # line is empty\n",
    "                continue                            # no need to add anything to the network\n",
    "            if G.has_node(hashtag_set[0]) == False: # hashtag does not exist in network\n",
    "                G.add_node(hashtag_set[0])          # add node to the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a list of sets that represent the communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "cset = list(nx_comm.label_propagation_communities(G))\n",
    "#print(cset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a function to give a weight threshold to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes in a graph and a weight threshold and returns a graph with only edges of weight >= thresh\n",
    "def weight_threshold(G,thresh):\n",
    "    # creaete a copy of the original graph\n",
    "    G_weight_thresh = nx.Graph()\n",
    "    G_weight_thresh = G.copy(as_view=False)\n",
    "        \n",
    "    for edge in G_weight_thresh.edges():                         # loop for every edge in the graph\n",
    "        if G_weight_thresh[edge[0]][edge[1]]['weight'] < thresh: # edge weight does no meet threshold\n",
    "            G_weight_thresh.remove_edge(edge[0],edge[1])         # remove edge\n",
    "    return G_weight_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a function to give a component size threshold to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes in a graph and a community size thresholds and removes nodes that are apart of a community of size <= thresh\n",
    "def comp_size_threshold(G,thresh):\n",
    "    # creaete a copy of the original graph\n",
    "    G_comp_thresh = nx.Graph()\n",
    "    G_comp_thresh = G.copy(as_view=False)\n",
    "    \n",
    "    for component in nx.connected_components(G): # loop over ever component in the graph\n",
    "        if len(component) < thresh:              # component does not meet threshold\n",
    "            for node in component:               # loop over every node in the component\n",
    "                G_comp_thresh.remove_node(node)  # remove all nodes from small component\n",
    "    return G_comp_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impose a weight threshold of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_w10 = weight_threshold(G,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ignore low weighted edges in terms of tweets/hashtags means to remove the connection between hashtags that do not appear in many tweets together. The edge weight threshold of 10 that is imposed means that in order for an edge to exist between hashtags, they must appear in at least 10 tweets together; any edge in the original network that represents two hashtags that appear in 9 or less tweets together is thrown out and not considered for the community detection. As the threshold is raised higher and higher the network is representing the hashtags that appear in a larger and larger number of tweets together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove components consisting of less than 10 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_w10_c10 = comp_size_threshold(G_w10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would make sense to remove small graph components from our community analysis becuase they could represent communities that are so small compared to the size of the graph that they are not significant to the network as a whole. An example of perhaps a mispelling of certain hashtags from a few different tweets could create a small component that would be deleted. But the community might miss a very small tightly-knit community that has been removed from the graph as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community detection with the new thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "cset_w10_c10 = list(nx_comm.label_propagation_communities(G_w10_c10))\n",
    "#print(cset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a histogram of the distribution in community sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comm_sizes = ['']*len(cset_w10_c10)           # create list with number of items equivalent to number of communities\n",
    "for idx,community in enumerate(cset_w10_c10): # loop over every community in the graph\n",
    "    comm_sizes[idx] = len(community)          # get community size\n",
    "    \n",
    "plt.hist(comm_sizes,20)\n",
    "plt.xlabel('community sizes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write the communities you've detected to htag_communities_w10_c10.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('htag_communities_w10_c10.txt' , 'w' , encoding='UTF-8') as fout: # open file to write communities to\n",
    "    for community in cset_w10_c10:                                          # repeat for every line from input file\n",
    "        community_str = ','.join(community)                                 # get single string from list of strings\n",
    "        fout.write('{%s}'%community_str)                                    # write space delimited communities to output file\n",
    "        fout.write('\\n')                                                    # new line between each entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A community that makes sense from this detection is {babys,kids,children} because all of these are roughly synonyms and it is easy to see why these hashtags would appear together in many tweets.\n",
    "A community that does not make sense is {urgent,cats,nyc} as there is seemingly no immediatley recognizeable relation between the three hashtags in this set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run community detection for the four quadrants of low/high weight/community thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph generation\n",
    "G_w_low = weight_threshold(G,5)         # low weight threshold\n",
    "G_w_high = weight_threshold(G,25)       # high weight threshold\n",
    "G_Q1 = comp_size_threshold(G_w_low,4)   # low c & low w\n",
    "G_Q2 = comp_size_threshold(G_w_high,4)  # low c & high w\n",
    "G_Q3 = comp_size_threshold(G_w_low,16)  # high c & low w\n",
    "G_Q4 = comp_size_threshold(G_w_high,16) # high c & high w\n",
    "\n",
    "# community detection\n",
    "cset_Q1 = list(nx_comm.label_propagation_communities(G_Q1))\n",
    "cset_Q2 = list(nx_comm.label_propagation_communities(G_Q2))\n",
    "cset_Q3 = list(nx_comm.label_propagation_communities(G_Q3))\n",
    "cset_Q4 = list(nx_comm.label_propagation_communities(G_Q4))\n",
    "\n",
    "# write out to text docs\n",
    "with open('htag_communities_Q1.txt' , 'w' , encoding='UTF-8') as fout: # open file to write communities to\n",
    "    for community in cset_Q1:                                          # repeat for every line from input file\n",
    "        community_str = ','.join(community)                            # get single string from list of strings\n",
    "        fout.write('{%s}'%community_str)                               # write space delimited communities to output file\n",
    "        fout.write('\\n')                                               # new line between each entry\n",
    "with open('htag_communities_Q2.txt' , 'w' , encoding='UTF-8') as fout:\n",
    "    for community in cset_Q2: \n",
    "        community_str = ','.join(community)\n",
    "        fout.write('{%s}'%community_str)\n",
    "        fout.write('\\n') \n",
    "with open('htag_communities_Q3.txt' , 'w' , encoding='UTF-8') as fout:\n",
    "    for community in cset_Q3: \n",
    "        community_str = ','.join(community) \n",
    "        fout.write('{%s}'%community_str) \n",
    "        fout.write('\\n') \n",
    "with open('htag_communities_Q4.txt' , 'w' , encoding='UTF-8') as fout:\n",
    "    for community in cset_Q4:\n",
    "        community_str = ','.join(community)\n",
    "        fout.write('{%s}'%community_str)\n",
    "        fout.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first quadrant of the graph has the least amount of restrictions on nodes and edges that can remain in the graph, so naturally it has the largest number of communities detected, and many of those communities hold a large number of nodes within them. This can be disadventageous as having many communities of large size means there is a higher chance that there are unrelated nodes within the same communitiy. An example of this is the communitity:\n",
    "\n",
    "{losangeles,kellyservices,stelle,retail,austin,regional,security,customer,jobs4u,supplychain,software,phoenix,accounting,businessmgmt,houston,montreal,account,roberthalf,engineer,engineering,technician,it,maintenance,hiring,portland,hr,developer,sanantonio,tampa,kellyjobs,physician,manufacturing,clerical,banking,jewellery,hospitality,sales,denver,indianapolis,parttime,seattle,columbus,jobs,cfgjobs,ca,veterans,transportation,healthcare,assistant,500k,intel,coordinator,glendale,job,birmingham,newyork,careerarc,service,dubai,toronto,time,london,income,entry,sanfrancisco,senior,cdl,atlanta,customerservice,charlotte,edmonton,recruitment,manager,sonic,accountemps,the,nursing}\n",
    "\n",
    "\n",
    "The second quadrant has a high weight threshold and a low component threshold. This means that many more edges are being eliminated. This also effects the component detection because the weight threshold is applied first, meaning that because many edges are removed, there may be components that decrease such that they are below the component size threshold when it is applied. Due to this there are many less communities detected and the communities that are detected have many fewer nodes. While it should be stated that important information can be left out like smaller communities and many large communties can be split up or incomplete, this quadrant can remove some nodes from communities that aren't strongly related. An example of a community in this quadrant that contains nodes that have very similar meanings is:\n",
    "\n",
    "{blackfriday,kohlssweepstakes,deals,cybermonday}\n",
    "\n",
    "\n",
    "The third quadrant has a low weight threshold and a high component threshold. As observed before, due to the weight threshold being implimented first, the the high threshold for community size has less of an effect than the high threshold for edge weight. This can be seen in the number of communities detected and the size of those communities, as there are many more communities, and they can be much larger in quadrant three than quadrant two. In comparison to queadrant one, the addition of the high component threshold decreases the number of communities but does not have as siginificant an effect on the size of the communities, specifically the larger communities. An example of this can be seen in the following community that is intact from quadrant one:\n",
    "\n",
    "{losangeles,kellyservices,stelle,retail,austin,regional,security,customer,jobs4u,supplychain,software,phoenix,accounting,businessmgmt,houston,montreal,account,roberthalf,engineer,engineering,technician,it,maintenance,hiring,portland,hr,developer,sanantonio,tampa,kellyjobs,physician,manufacturing,clerical,banking,jewellery,hospitality,sales,denver,indianapolis,parttime,seattle,columbus,jobs,cfgjobs,ca,veterans,transportation,healthcare,assistant,500k,intel,coordinator,glendale,job,birmingham,newyork,careerarc,service,dubai,toronto,time,london,income,entry,sanfrancisco,senior,cdl,atlanta,customerservice,charlotte,edmonton,recruitment,manager,sonic,accountemps,the,nursing}\n",
    "\n",
    "\n",
    "The fourth quadrant has the most restrictions on nodes and edges that can remain in the graph, so naturally it has the least number of communities, and of those communities they are much smaller than in the other quadrants. This can be seen as an advantage by ridding the graph of the most outliers and show only the strongest connected nodes from the graph, but this can also be seen as a disadvantage as large amounts of useful information is thrown away. An example of this is the following community, that while the two hashtags are very closely related, it would be expected that there would be many more hashtags that would be very similar and co-occur with them often:\n",
    "\n",
    "{happythanksgiving,iamthankfulfor}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick a topic/theme that you see in the data and find the communities that correspond bes to that topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topic: sports\n",
    "\n",
    "Q1:\n",
    "{liverpool,sturridge,liderbeÅiktaÅ,0,girondins,bordeaux,lfcfrance,ynwa,molfen,klopp,bor,ajax,lfc,lfcindonesia,uel,mfkvsfbsk,celaja,diadesporting,lfcbou,cerny,fenerbahÃ§e,livbor,beÅiktaÅ,vilvscr}\n",
    "{panthernation,colorrush,dabonthemfolks,dabonthemturkey,tgiving,carvsdal,interception}\n",
    "{gopanthers,panthersnation,luuuuke,keepp,keeppounding}\n",
    "{wedemboyz,gocowboys,dallascowboys,cowboysnation}\n",
    "{browns,cleveland}\n",
    "{dalvscar,fieldgoal,panthers,cowboys,nflthanksgiving,touchdown,chivsgb,th4nksgiving}\n",
    "{card,soccer,cards,football,espn,topps,jersey,nfl}\n",
    "{nike,retro,sport}\n",
    "{basketball,nba}\n",
    "{lions,eagles}\n",
    "{carolina,dallas}\n",
    "{europaleague,hommage,celtic,coys}\n",
    "{bears,packers}\n",
    "{mobile,playfantasyfootball}\n",
    "{wjc2015,worldjuniors}\n",
    "{nflfootball,yahoosports}\n",
    "{nbfootball,holdnothingback}\n",
    "\n",
    "\n",
    "Q2:\n",
    "{colorrush,panthers,cowboys,carvsdal,nfl}\n",
    "{ynwa,liverpool,lfc,livbor,europaleague,bordeaux}\n",
    "\n",
    "\n",
    "Q3:\n",
    "{liverpool,sturridge,liderbeÅiktaÅ,0,girondins,bordeaux,lfcfrance,ynwa,molfen,klopp,bor,ajax,lfc,lfcindonesia,uel,mfkvsfbsk,celaja,diadesporting,lfcbou,cerny,fenerbahÃ§e,livbor,beÅiktaÅ,vilvscr}\n",
    "{panthernation,colorrush,dabonthemfolks,dabonthemturkey,tgiving,carvsdal,interception}\n",
    "{gopanthers,panthersnation,luuuuke,keepp,keeppounding}\n",
    "{wedemboyz,gocowboys,dallascowboys,cowboysnation}\n",
    "{browns,cleveland}\n",
    "{dalvscar,fieldgoal,panthers,cowboys,nflthanksgiving,touchdown,chivsgb,th4nksgiving}\n",
    "{card,soccer,cards,football,espn,topps,jersey,nfl}\n",
    "{nike,retro,sport}\n",
    "{basketball,nba}\n",
    "{lions,eagles}\n",
    "{carolina,dallas}\n",
    "{europaleague,hommage,celtic,coys}\n",
    "{bears,packers}\n",
    "{mobile,playfantasyfootball}\n",
    "{wjc2015,worldjuniors}\n",
    "{nflfootball,yahoosports}\n",
    "{nbfootball,holdnothingback}\n",
    "\n",
    "\n",
    "Q4:\n",
    "{colorrush,panthers,cowboys,carvsdal,nfl}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which threshold has communities that best represent the topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quadrants 1 and three have communities that best represent the topic because there are many more communities that the others have ignored that relate many different topics within sports together without many extraneous nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there a threshhold that is clearly the best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most promising of the group is quadrant three because it gives lots of information and that other quadrants ignore while still having a threshold to prevent outliers from making a large impact"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
